{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "import gensim\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import re,string,unicodedata\n",
        "\n",
        "from bs4 import BeautifulSoup\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from wordcloud import WordCloud,STOPWORDS\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "from gensim.utils import simple_preprocess \n",
        "from gensim.models import Phrases, Word2Vec\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "from nltk.tokenize import word_tokenize,sent_tokenize\n",
        "\n",
        "\n",
        "nltk.download('stopwords')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yd8D9Zb_vspT",
        "outputId": "dbb978e1-6871-42ed-9c07-7203155e269b"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the IMDb dataset from the CSV file\n",
        "imdb_df = pd.read_csv('/content/irony-labeled.csv', header=None, names=['comment_text', 'label'])\n",
        "imdb_df[\"label\"] = np.where(imdb_df[\"label\"] == \"-1\", 1, 0)\n",
        "\n",
        "gen_df = pd.read_csv('/GEN-sarc-notsarc.csv', header=None, names=['class', 'text'])\n",
        "gen_df = gen_df.append(pd.read_csv('/HYP-sarc-notsarc.csv'))\n",
        "gen_df = gen_df.append(pd.read_csv('/RQ-sarc-notsarc.csv'))\n",
        "\n",
        "gen_df[\"class\"] = np.where(gen_df[\"class\"] == \"notsarc\", 0, 1)\n",
        "\n",
        "stop = set(stopwords.words('english'))\n",
        "punctuation = list(string.punctuation)\n",
        "stop.update(punctuation)\n",
        "\n",
        "# Preprocess the dataset\n",
        "def strip_html(text):\n",
        "    soup = BeautifulSoup(text, \"html.parser\")\n",
        "    return soup.get_text()\n",
        "\n",
        "#Removing the square brackets\n",
        "def remove_between_square_brackets(text):\n",
        "    return re.sub('\\[[^]]*\\]', '', text)\n",
        "# Removing URL's\n",
        "def remove_between_square_brackets(text):\n",
        "    return re.sub(r'http\\S+', '', text)\n",
        "#Removing the stopwords from text\n",
        "def remove_stopwords(text):\n",
        "    final_text = []\n",
        "    for i in text.split():\n",
        "        if i.strip().lower() not in stop:\n",
        "            final_text.append(i.strip())\n",
        "    return \" \".join(final_text)\n",
        "#Removing the noisy text\n",
        "def denoise_text(text):\n",
        "    text = strip_html(text)\n",
        "    text = remove_between_square_brackets(text)\n",
        "    text = remove_stopwords(text)\n",
        "    return text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KmS_uZMhviOp",
        "outputId": "66066200-1fa7-4ff0-a109-7be1a204f4a3"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-29-a42077d2f61c>:6: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  gen_df = gen_df.append(pd.read_csv('/HYP-sarc-notsarc.csv'))\n",
            "<ipython-input-29-a42077d2f61c>:7: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  gen_df = gen_df.append(pd.read_csv('/RQ-sarc-notsarc.csv'))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "imdb_df['comment_text']=imdb_df['comment_text'].apply(denoise_text)\n",
        "gen_df['text']=gen_df['text'].apply(denoise_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yrm4JS6hwoqc",
        "outputId": "b3f58fcb-7fa9-4c2b-990d-2e915667a8c7"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-29-a42077d2f61c>:17: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
            "  soup = BeautifulSoup(text, \"html.parser\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "words, imdb_words, gen_words = [], [], []\n",
        "for i in imdb_df.comment_text.values:\n",
        "    words.append(i.split())\n",
        "    imdb_words.append(i.split())\n",
        "words=words[1:]\n",
        "\n",
        "for i in gen_df.text.values:\n",
        "    words.append(i.split())\n",
        "    gen_words.append(i.split())"
      ],
      "metadata": {
        "id": "pp7HQIkewzF4"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4KvgCffDwhfh",
        "outputId": "6a8a4801-e07d-4797-d860-d8959dfa019e"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "11336"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "imdb_wv_model = Word2Vec(words, vector_size=100, window=3, min_count=1, workers=16)"
      ],
      "metadata": {
        "id": "0HwrOy-J29y2"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(imdb_wv_model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7RkjUghZ3ORS",
        "outputId": "2f1cbab2-47bc-445f-e499-779accd182f2"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Word2Vec<vocab=53846, vector_size=100, alpha=0.025>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(words))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iPVUi1Nz7b4W",
        "outputId": "14f4b09f-cbb7-4ff3-ccfb-4771440e5496"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "11336\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import keras\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "\n",
        "tokenizer = Tokenizer(53846)\n",
        "tokenizer.fit_on_texts(words)\n",
        "text = tokenizer.texts_to_sequences(words)\n",
        "text = keras.utils.pad_sequences(text, 50)\n",
        "\n",
        "print(text[:2])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L67LkbKU3PbY",
        "outputId": "94929b4a-1507-46a9-efaa-a3d5f03fa66d"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[    0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0   840   610  7758  5688   668   192     3  5689    86\n",
            "    359  1035  4569 19649 19650 19651   100  2416  5058  1239  4570 19652\n",
            "    289     8  5690   777   206   668 12542   381  1688   175  2000   175\n",
            "    329   516]\n",
            " [  528   424 19653   134    26   757  1317  5059   841   117  2292   517\n",
            "    107  1450 19654  3540   669   311 19655  2293   710  1171   257  9557\n",
            "   2894     8 19656 19657     8  7759 12543 19658 19659  2293   710  2894\n",
            "   1567   378    64    76  5060    17  4571  9558    92    27  4158   469\n",
            "   6613  4571]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y = imdb_df[\"label\"]"
      ],
      "metadata": {
        "id": "QJA50BEmCoWh"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all(y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4NjH1pB2xg_f",
        "outputId": "07a5dea3-cbe6-4053-e252-36b4032d0e29"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "txt = tokenizer.texts_to_sequences(imdb_words)\n",
        "txt = keras.utils.pad_sequences(txt, 50)\n",
        "\n",
        "txt[:2]"
      ],
      "metadata": {
        "id": "RacOsXm2hZ1r",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cc6ab148-e8c0-490b-8c6d-9dd0d94cc755"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[    0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0],\n",
              "       [    0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,   840,   610,  7758,\n",
              "         5688,   668,   192,     3,  5689,    86,   359,  1035,  4569,\n",
              "        19649, 19650, 19651,   100,  2416,  5058,  1239,  4570, 19652,\n",
              "          289,     8,  5690,   777,   206,   668, 12542,   381,  1688,\n",
              "          175,  2000,   175,   329,   516]], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(np.array(txt), np.array(y), train_size=0.8, stratify=y)"
      ],
      "metadata": {
        "id": "Qqh1HMzg4IP0"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "model = keras.models.Sequential([\n",
        "\n",
        "    # Embedding layer\n",
        "    keras.layers.Embedding(input_dim=len(imdb_wv_model.wv.key_to_index),\n",
        "                            output_dim=100,\n",
        "                            input_length=50,\n",
        "                            weights=[imdb_wv_model.wv.vectors],\n",
        "                            trainable=True),\n",
        "    \n",
        "    keras.layers.Dropout(0.2),\n",
        "\n",
        "    # BiLSTM layer\n",
        "    keras.layers.Bidirectional(keras.layers.LSTM(128, return_sequences=True)),\n",
        "\n",
        "    keras.layers.Bidirectional(keras.layers.LSTM(64)),\n",
        "\n",
        "    keras.layers.Dropout(0.2),\n",
        "\n",
        "    keras.layers.Dense(200),\n",
        "\n",
        "    keras.layers.Activation('relu'),\n",
        "\n",
        "    keras.layers.Dropout(0.2),\n",
        "    \n",
        "    # Output layer\n",
        "    keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model.summary()\n",
        "\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy', keras.metrics.Precision(), keras.metrics.Recall()])\n",
        "\n",
        "model.fit(x_train, y_train, validation_data=(x_test, y_test), epochs=10, batch_size=64)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sSvtr3TQ14YU",
        "outputId": "1e5a3ca8-158b-4767-8a85-6acf63fb1010"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, 50, 100)           5384600   \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 50, 100)           0         \n",
            "                                                                 \n",
            " bidirectional (Bidirectiona  (None, 50, 256)          234496    \n",
            " l)                                                              \n",
            "                                                                 \n",
            " bidirectional_1 (Bidirectio  (None, 128)              164352    \n",
            " nal)                                                            \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 128)               0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 200)               25800     \n",
            "                                                                 \n",
            " activation (Activation)     (None, 200)               0         \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 200)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1)                 201       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5,809,449\n",
            "Trainable params: 5,809,449\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "25/25 [==============================] - 22s 306ms/step - loss: 0.6023 - accuracy: 0.7186 - precision: 0.7236 - recall: 0.9894 - val_loss: 0.5898 - val_accuracy: 0.7231 - val_precision: 0.7231 - val_recall: 1.0000\n",
            "Epoch 2/10\n",
            "25/25 [==============================] - 5s 209ms/step - loss: 0.5824 - accuracy: 0.7250 - precision: 0.7248 - recall: 1.0000 - val_loss: 0.5797 - val_accuracy: 0.7231 - val_precision: 0.7231 - val_recall: 1.0000\n",
            "Epoch 3/10\n",
            "25/25 [==============================] - 5s 196ms/step - loss: 0.5824 - accuracy: 0.7244 - precision: 0.7249 - recall: 0.9982 - val_loss: 0.5788 - val_accuracy: 0.7231 - val_precision: 0.7231 - val_recall: 1.0000\n",
            "Epoch 4/10\n",
            "25/25 [==============================] - 5s 181ms/step - loss: 0.5727 - accuracy: 0.7244 - precision: 0.7244 - recall: 1.0000 - val_loss: 0.5821 - val_accuracy: 0.7231 - val_precision: 0.7231 - val_recall: 1.0000\n",
            "Epoch 5/10\n",
            "25/25 [==============================] - 6s 227ms/step - loss: 0.5585 - accuracy: 0.7269 - precision: 0.7262 - recall: 1.0000 - val_loss: 0.5764 - val_accuracy: 0.7231 - val_precision: 0.7231 - val_recall: 1.0000\n",
            "Epoch 6/10\n",
            "25/25 [==============================] - 4s 150ms/step - loss: 0.2670 - accuracy: 0.8859 - precision: 0.8864 - recall: 0.9664 - val_loss: 1.1834 - val_accuracy: 0.5282 - val_precision: 0.7500 - val_recall: 0.5213\n",
            "Epoch 7/10\n",
            "25/25 [==============================] - 4s 181ms/step - loss: 0.0861 - accuracy: 0.9679 - precision: 0.9770 - recall: 0.9788 - val_loss: 1.2337 - val_accuracy: 0.6179 - val_precision: 0.7418 - val_recall: 0.7234\n",
            "Epoch 8/10\n",
            "25/25 [==============================] - 4s 170ms/step - loss: 0.0452 - accuracy: 0.9833 - precision: 0.9851 - recall: 0.9920 - val_loss: 1.4772 - val_accuracy: 0.7000 - val_precision: 0.7419 - val_recall: 0.8972\n",
            "Epoch 9/10\n",
            "25/25 [==============================] - 3s 125ms/step - loss: 0.0190 - accuracy: 0.9929 - precision: 0.9938 - recall: 0.9965 - val_loss: 1.6347 - val_accuracy: 0.6846 - val_precision: 0.7345 - val_recall: 0.8830\n",
            "Epoch 10/10\n",
            "25/25 [==============================] - 5s 192ms/step - loss: 0.0050 - accuracy: 0.9987 - precision: 0.9991 - recall: 0.9991 - val_loss: 2.0252 - val_accuracy: 0.6667 - val_precision: 0.7517 - val_recall: 0.8050\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f9bec1a6eb0>"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "val_recall = 0.8160\n",
        "val_precision = 0.8572\n",
        "val_f1 = (2 * val_precision * val_recall) / (val_precision + val_recall)\n",
        "\n",
        "val_f1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7YcCleAvkJ4s",
        "outputId": "cbdff001-3b26-4d8e-cfae-1c1892773e0c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8360927563949319"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "txt2 = tokenizer.texts_to_sequences(gen_words)\n",
        "txt2 = keras.utils.pad_sequences(txt2, 50)\n",
        "\n",
        "y = gen_df[\"class\"]\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(np.array(txt2), np.array(y), train_size=0.8, stratify=y)\n",
        "\n",
        "model.fit(x_train, y_train, validation_data=(x_test, y_test), epochs=10)"
      ],
      "metadata": {
        "id": "K-q-Fpsl97A0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "100f15f9-e409-4a09-fb33-65cca6985249"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "235/235 [==============================] - 37s 158ms/step - loss: 0.4500 - accuracy: 0.8465 - precision: 0.8474 - recall: 0.9986 - val_loss: 0.4125 - val_accuracy: 0.8472 - val_precision: 0.8472 - val_recall: 1.0000\n",
            "Epoch 2/10\n",
            "235/235 [==============================] - 17s 73ms/step - loss: 0.3273 - accuracy: 0.8776 - precision: 0.8860 - recall: 0.9819 - val_loss: 0.5256 - val_accuracy: 0.7971 - val_precision: 0.8513 - val_recall: 0.9214\n",
            "Epoch 3/10\n",
            "235/235 [==============================] - 10s 44ms/step - loss: 0.1039 - accuracy: 0.9636 - precision: 0.9749 - recall: 0.9824 - val_loss: 0.8691 - val_accuracy: 0.6917 - val_precision: 0.8519 - val_recall: 0.7700\n",
            "Epoch 4/10\n",
            "235/235 [==============================] - 10s 42ms/step - loss: 0.0441 - accuracy: 0.9850 - precision: 0.9920 - recall: 0.9903 - val_loss: 0.9550 - val_accuracy: 0.6581 - val_precision: 0.8549 - val_recall: 0.7184\n",
            "Epoch 5/10\n",
            "235/235 [==============================] - 6s 25ms/step - loss: 0.0309 - accuracy: 0.9879 - precision: 0.9948 - recall: 0.9909 - val_loss: 0.9206 - val_accuracy: 0.7274 - val_precision: 0.8556 - val_recall: 0.8158\n",
            "Epoch 6/10\n",
            "235/235 [==============================] - 6s 24ms/step - loss: 0.0257 - accuracy: 0.9877 - precision: 0.9942 - recall: 0.9914 - val_loss: 0.9147 - val_accuracy: 0.6358 - val_precision: 0.8568 - val_recall: 0.6845\n",
            "Epoch 7/10\n",
            "235/235 [==============================] - 5s 22ms/step - loss: 0.0193 - accuracy: 0.9891 - precision: 0.9959 - recall: 0.9912 - val_loss: 1.1096 - val_accuracy: 0.6571 - val_precision: 0.8563 - val_recall: 0.7153\n",
            "Epoch 8/10\n",
            "235/235 [==============================] - 6s 27ms/step - loss: 0.0160 - accuracy: 0.9891 - precision: 0.9942 - recall: 0.9929 - val_loss: 1.0833 - val_accuracy: 0.6454 - val_precision: 0.8582 - val_recall: 0.6964\n",
            "Epoch 9/10\n",
            "235/235 [==============================] - 4s 18ms/step - loss: 0.0194 - accuracy: 0.9891 - precision: 0.9932 - recall: 0.9939 - val_loss: 1.1865 - val_accuracy: 0.7151 - val_precision: 0.8455 - val_recall: 0.8121\n",
            "Epoch 10/10\n",
            "235/235 [==============================] - 6s 25ms/step - loss: 0.0153 - accuracy: 0.9889 - precision: 0.9931 - recall: 0.9939 - val_loss: 1.1696 - val_accuracy: 0.7428 - val_precision: 0.8511 - val_recall: 0.8441\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f9bead0fc40>"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "val_recall = 0.8511 *100\n",
        "val_precision = 0.8441 *100\n",
        "val_f1 = (2 * val_precision * val_recall) / (val_precision + val_recall)\n",
        "\n",
        "val_f1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iP0PzAn7krA9",
        "outputId": "ba1bbef3-e380-40c4-9203-0eeb3358daa6"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "84.75855474280321"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save(\"/bilstm-with-intermediate-task-irony.h\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pfxrQD7Xl-cc",
        "outputId": "8fc6036c-9b90-427d-c734-d8b9365368ea"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_4_layer_call_fn while saving (showing 5 of 8). These functions will not be directly callable after loading.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gen_wv_model = Word2Vec(gen_words, vector_size=100, window=3, min_count=1, workers=16)"
      ],
      "metadata": {
        "id": "JYfXu-htBH_e"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(gen_wv_model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-cf_G0T5BNyd",
        "outputId": "17f4713d-3f80-43d9-b071-5e57f91699d0"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Word2Vec<vocab=46908, vector_size=100, alpha=0.025>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# tokenizer = Tokenizer(46908)\n",
        "# tokenizer.fit_on_texts(gen_words)\n",
        "txt2 = tokenizer.texts_to_sequences(gen_words)\n",
        "txt2 = keras.utils.pad_sequences(txt2, 50)\n",
        "\n",
        "model = keras.models.Sequential([\n",
        "\n",
        "    # Embedding layer\n",
        "    keras.layers.Embedding(input_dim=len(imdb_wv_model.wv.key_to_index),\n",
        "                            output_dim=100,\n",
        "                            input_length=50,\n",
        "                            weights=[imdb_wv_model.wv.vectors],\n",
        "                            trainable=True),\n",
        "    \n",
        "    keras.layers.Dropout(0.2),\n",
        "\n",
        "    # BiLSTM layer\n",
        "    keras.layers.Bidirectional(keras.layers.LSTM(128, return_sequences=True)),\n",
        "\n",
        "    keras.layers.Bidirectional(keras.layers.LSTM(64)),\n",
        "\n",
        "    keras.layers.Dropout(0.2),\n",
        "\n",
        "    keras.layers.Dense(200),\n",
        "\n",
        "    keras.layers.Activation('relu'),\n",
        "\n",
        "    keras.layers.Dropout(0.2),\n",
        "    \n",
        "    # Output layer\n",
        "    keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "\n",
        "y = gen_df[\"class\"]\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(np.array(txt2), np.array(y), train_size=0.8, stratify=y, random_state=42)\n",
        "\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy', keras.metrics.Precision(), keras.metrics.Recall()])\n",
        "\n",
        "model.fit(x_train, y_train, validation_data=(x_test, y_test), epochs=10, batch_size=64)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XKkAgrQOF-0I",
        "outputId": "230d274a-de94-46aa-8c88-18ebe2c850b8"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "118/118 [==============================] - 34s 212ms/step - loss: 0.4230 - accuracy: 0.8474 - precision_1: 0.8474 - recall_1: 1.0000 - val_loss: 0.4391 - val_accuracy: 0.8472 - val_precision_1: 0.8472 - val_recall_1: 1.0000\n",
            "Epoch 2/10\n",
            "118/118 [==============================] - 17s 148ms/step - loss: 0.4149 - accuracy: 0.8474 - precision_1: 0.8474 - recall_1: 1.0000 - val_loss: 0.4131 - val_accuracy: 0.8472 - val_precision_1: 0.8472 - val_recall_1: 1.0000\n",
            "Epoch 3/10\n",
            "118/118 [==============================] - 10s 85ms/step - loss: 0.2181 - accuracy: 0.9134 - precision_1: 0.9316 - recall_1: 0.9690 - val_loss: 0.5392 - val_accuracy: 0.8099 - val_precision_1: 0.8579 - val_recall_1: 0.9296\n",
            "Epoch 4/10\n",
            "118/118 [==============================] - 10s 84ms/step - loss: 0.0634 - accuracy: 0.9806 - precision_1: 0.9895 - recall_1: 0.9876 - val_loss: 0.6430 - val_accuracy: 0.7726 - val_precision_1: 0.8642 - val_recall_1: 0.8680\n",
            "Epoch 5/10\n",
            "118/118 [==============================] - 8s 67ms/step - loss: 0.0399 - accuracy: 0.9884 - precision_1: 0.9953 - recall_1: 0.9910 - val_loss: 0.7444 - val_accuracy: 0.7135 - val_precision_1: 0.8695 - val_recall_1: 0.7788\n",
            "Epoch 6/10\n",
            "118/118 [==============================] - 6s 49ms/step - loss: 0.0277 - accuracy: 0.9885 - precision_1: 0.9956 - recall_1: 0.9909 - val_loss: 0.7279 - val_accuracy: 0.7476 - val_precision_1: 0.8592 - val_recall_1: 0.8397\n",
            "Epoch 7/10\n",
            "118/118 [==============================] - 5s 37ms/step - loss: 0.0220 - accuracy: 0.9891 - precision_1: 0.9951 - recall_1: 0.9920 - val_loss: 0.9722 - val_accuracy: 0.7529 - val_precision_1: 0.8582 - val_recall_1: 0.8485\n",
            "Epoch 8/10\n",
            "118/118 [==============================] - 5s 44ms/step - loss: 0.0177 - accuracy: 0.9899 - precision_1: 0.9964 - recall_1: 0.9917 - val_loss: 0.8598 - val_accuracy: 0.7348 - val_precision_1: 0.8598 - val_recall_1: 0.8209\n",
            "Epoch 9/10\n",
            "118/118 [==============================] - 4s 35ms/step - loss: 0.0149 - accuracy: 0.9896 - precision_1: 0.9934 - recall_1: 0.9943 - val_loss: 1.1400 - val_accuracy: 0.7609 - val_precision_1: 0.8564 - val_recall_1: 0.8624\n",
            "Epoch 10/10\n",
            "118/118 [==============================] - 4s 30ms/step - loss: 0.0160 - accuracy: 0.9901 - precision_1: 0.9956 - recall_1: 0.9928 - val_loss: 1.0674 - val_accuracy: 0.7252 - val_precision_1: 0.8576 - val_recall_1: 0.8102\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f9afaf59580>"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "val_recall = 0.8576 *100\n",
        "val_precision = 0.8102 *100\n",
        "val_f1 = (2 * val_precision * val_recall) / (val_precision + val_recall)\n",
        "\n",
        "val_f1"
      ],
      "metadata": {
        "id": "zzCxsmZkAuoD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3cfe109c-e935-4725-ef8f-1f4d3f428559"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "83.32264300275813"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r \"/bilstm.zip\" \"/bert-with-intermediate-task.h\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "llUwZ02NtfpW",
        "outputId": "c380ba45-0100-4957-9157-e8f186db2d37"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: bert-with-intermediate-task.h/ (stored 0%)\n",
            "  adding: bert-with-intermediate-task.h/assets/ (stored 0%)\n",
            "  adding: bert-with-intermediate-task.h/keras_metadata.pb (deflated 92%)\n",
            "  adding: bert-with-intermediate-task.h/variables/ (stored 0%)\n",
            "  adding: bert-with-intermediate-task.h/variables/variables.index (deflated 67%)\n",
            "  adding: bert-with-intermediate-task.h/variables/variables.data-00000-of-00001 (deflated 48%)\n",
            "  adding: bert-with-intermediate-task.h/fingerprint.pb (stored 0%)\n",
            "  adding: bert-with-intermediate-task.h/saved_model.pb (deflated 90%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ehjAu4Urt4zE"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}