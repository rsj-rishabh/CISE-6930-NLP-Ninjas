{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "acbff53c-ccea-4f26-b901-24e589aee6f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>comment</th>\n",
       "      <th>author</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>score</th>\n",
       "      <th>ups</th>\n",
       "      <th>downs</th>\n",
       "      <th>date</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>parent_comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Bushie the other Bushie the next Bushie the af...</td>\n",
       "      <td>selicos</td>\n",
       "      <td>politics</td>\n",
       "      <td>606</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>2016-10</td>\n",
       "      <td>2016-10-13 02:39:41</td>\n",
       "      <td>Don't you mean, Bushie the Younger?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Congrats on getting such damage before they we...</td>\n",
       "      <td>SenGenketsu</td>\n",
       "      <td>Robocraft</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>2016-10</td>\n",
       "      <td>2016-10-27 16:51:51</td>\n",
       "      <td>So, Flak will be a thing again? Than i have to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>Keeper of the Grove too</td>\n",
       "      <td>pucykoks</td>\n",
       "      <td>hearthstone</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-09</td>\n",
       "      <td>2016-09-13 21:33:07</td>\n",
       "      <td>Especially when you compare it to dalaran Mage...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>'This would be like my form of alcoholism' cle...</td>\n",
       "      <td>redditzendave</td>\n",
       "      <td>politics</td>\n",
       "      <td>7</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>2016-10</td>\n",
       "      <td>2016-10-21 19:16:31</td>\n",
       "      <td>See It: Trump hires teen because she's beautif...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>Great input</td>\n",
       "      <td>Karieo</td>\n",
       "      <td>wow</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-09</td>\n",
       "      <td>2016-09-19 20:54:15</td>\n",
       "      <td>you swap to druid.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99995</th>\n",
       "      <td>0</td>\n",
       "      <td>Alright lmao, a bit *too* gay for my tastes</td>\n",
       "      <td>ScootaliciousScooter</td>\n",
       "      <td>teenagers</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>2016-12</td>\n",
       "      <td>2016-12-30 04:05:43</td>\n",
       "      <td>This is just getting too far, sort of like you...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99996</th>\n",
       "      <td>1</td>\n",
       "      <td>Rip this is the farthest I've ever gotten</td>\n",
       "      <td>EmceeSexy</td>\n",
       "      <td>teenagers</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>2016-12</td>\n",
       "      <td>2016-12-05 02:18:19</td>\n",
       "      <td>ok</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99997</th>\n",
       "      <td>1</td>\n",
       "      <td>Was expecting a tutorial on how to doxx your d...</td>\n",
       "      <td>Orrangejuiced</td>\n",
       "      <td>h1z1</td>\n",
       "      <td>3</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>2016-12</td>\n",
       "      <td>2016-12-07 04:48:41</td>\n",
       "      <td>Ninja tutorial</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99998</th>\n",
       "      <td>1</td>\n",
       "      <td>He just wants more time to prepare for playing...</td>\n",
       "      <td>bamachine</td>\n",
       "      <td>CFB</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>2016-11</td>\n",
       "      <td>2016-11-23 03:55:23</td>\n",
       "      <td>Coaches Poll: Most feel Jimbo Fisher leaves fo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99999</th>\n",
       "      <td>0</td>\n",
       "      <td>shit I am, well it isnt usual for me to see pe...</td>\n",
       "      <td>SFM_dude</td>\n",
       "      <td>StardustCrusaders</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-09</td>\n",
       "      <td>2016-09-20 17:43:20</td>\n",
       "      <td>Because I think you're confusing Peter Pan wit...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100000 rows Ã— 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       label                                            comment  \\\n",
       "0          0  Bushie the other Bushie the next Bushie the af...   \n",
       "1          1  Congrats on getting such damage before they we...   \n",
       "2          0                            Keeper of the Grove too   \n",
       "3          1  'This would be like my form of alcoholism' cle...   \n",
       "4          1                                        Great input   \n",
       "...      ...                                                ...   \n",
       "99995      0        Alright lmao, a bit *too* gay for my tastes   \n",
       "99996      1          Rip this is the farthest I've ever gotten   \n",
       "99997      1  Was expecting a tutorial on how to doxx your d...   \n",
       "99998      1  He just wants more time to prepare for playing...   \n",
       "99999      0  shit I am, well it isnt usual for me to see pe...   \n",
       "\n",
       "                     author          subreddit  score  ups  downs     date  \\\n",
       "0                   selicos           politics    606   -1     -1  2016-10   \n",
       "1               SenGenketsu          Robocraft      1   -1     -1  2016-10   \n",
       "2                  pucykoks        hearthstone     14   14      0  2016-09   \n",
       "3             redditzendave           politics      7   -1     -1  2016-10   \n",
       "4                    Karieo                wow      2    2      0  2016-09   \n",
       "...                     ...                ...    ...  ...    ...      ...   \n",
       "99995  ScootaliciousScooter          teenagers      2   -1     -1  2016-12   \n",
       "99996             EmceeSexy          teenagers      1   -1     -1  2016-12   \n",
       "99997         Orrangejuiced               h1z1      3   -1     -1  2016-12   \n",
       "99998             bamachine                CFB      2   -1     -1  2016-11   \n",
       "99999              SFM_dude  StardustCrusaders      6    6      0  2016-09   \n",
       "\n",
       "               created_utc                                     parent_comment  \n",
       "0      2016-10-13 02:39:41                Don't you mean, Bushie the Younger?  \n",
       "1      2016-10-27 16:51:51  So, Flak will be a thing again? Than i have to...  \n",
       "2      2016-09-13 21:33:07  Especially when you compare it to dalaran Mage...  \n",
       "3      2016-10-21 19:16:31  See It: Trump hires teen because she's beautif...  \n",
       "4      2016-09-19 20:54:15                                 you swap to druid.  \n",
       "...                    ...                                                ...  \n",
       "99995  2016-12-30 04:05:43  This is just getting too far, sort of like you...  \n",
       "99996  2016-12-05 02:18:19                                                 ok  \n",
       "99997  2016-12-07 04:48:41                                     Ninja tutorial  \n",
       "99998  2016-11-23 03:55:23  Coaches Poll: Most feel Jimbo Fisher leaves fo...  \n",
       "99999  2016-09-20 17:43:20  Because I think you're confusing Peter Pan wit...  \n",
       "\n",
       "[100000 rows x 10 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# import os\n",
    "# import shutil\n",
    "\n",
    "# import tensorflow as tf\n",
    "# import tensorflow_hub as hub\n",
    "# import tensorflow_text as text\n",
    "# from official.nlp import optimization  # to create AdamW optimizer\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df = pd.read_csv(r'sarcasm_subset.csv')\n",
    "frames = [df]\n",
    "full = pd.concat(frames)\n",
    "full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "4c126e9b-2e25-40e3-9e9c-9ff558f087e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_data = list(df[\"comment\"])[:5000]\n",
    "class_data = df[\"label\"].to_numpy()[:5000]\n",
    "for i in range(len(class_data)):\n",
    "    if class_data[i]=='notsarc':\n",
    "        class_data[i]=0\n",
    "    else:\n",
    "        class_data[i]=1\n",
    "        \n",
    "# for i in text_data:\n",
    "#     print(type(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "4b56b027-6f26-4286-85b7-0f1a60d2709b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  77.34 %\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from transformers import BertTokenizer, BertModel\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Load the pre-trained BERT model and tokenizer\n",
    "model = torch.load('BERT.pth')\n",
    "model.to(device)\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Define the classification model\n",
    "class BertClassifier(nn.Module):\n",
    "    def __init__(self, bert_model, num_classes):\n",
    "        super(BertClassifier, self).__init__()\n",
    "        self.bert = bert_model\n",
    "        self.fc = nn.Linear(768, num_classes)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        pooled_output = outputs[1]\n",
    "        logits = self.fc(pooled_output)\n",
    "        return logits\n",
    "\n",
    "# Load the training data\n",
    "# train_texts = [\"Example sentence 1\", \"Example sentence 2\", ...]\n",
    "# train_labels = [0, 1, ...]\n",
    "\n",
    "# Tokenize the text data\n",
    "train_encodings = tokenizer(list(text_data), padding=True, truncation=True, max_length=128)\n",
    "train_dataset = torch.utils.data.TensorDataset(\n",
    "    torch.tensor(train_encodings['input_ids']),\n",
    "    torch.tensor(train_encodings['attention_mask']),\n",
    "    torch.tensor(list(class_data))\n",
    ")\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "acc = []\n",
    "for idx, batch in enumerate(train_loader):\n",
    "    outputs = model(input_ids=batch[0].to(device), attention_mask=batch[1].to(device))\n",
    "    outputs = torch.argmax(outputs, axis = 1)\n",
    "    acc.append((outputs.cpu() == batch[2]).float().sum().numpy())\n",
    "    \n",
    "print(\"Accuracy: \", (sum(acc) / 5000) * 100, \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "0940df5e-b29c-47d7-90f0-25b5db5edd8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  64.86 %\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Load the pre-trained BERT model and tokenizer\n",
    "model = torch.load('RoBERTa.pth')\n",
    "model.to(device)\n",
    "tokenizer = AutoTokenizer.from_pretrained('roberta-base')\n",
    "\n",
    "# Define the classification model\n",
    "class BertClassifier(nn.Module):\n",
    "    def __init__(self, bert_model, num_classes):\n",
    "        super(BertClassifier, self).__init__()\n",
    "        self.bert = bert_model\n",
    "        self.fc = nn.Linear(768, num_classes)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        pooled_output = outputs[1]\n",
    "        logits = self.fc(pooled_output)\n",
    "        return logits\n",
    "\n",
    "# Load the training data\n",
    "# train_texts = [\"Example sentence 1\", \"Example sentence 2\", ...]\n",
    "# train_labels = [0, 1, ...]\n",
    "\n",
    "# Tokenize the text data\n",
    "train_encodings = tokenizer(list(text_data), padding=True, truncation=True, max_length=128)\n",
    "train_dataset = torch.utils.data.TensorDataset(\n",
    "    torch.tensor(train_encodings['input_ids']),\n",
    "    torch.tensor(train_encodings['attention_mask']),\n",
    "    torch.tensor(list(class_data))\n",
    ")\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "acc = []\n",
    "for idx, batch in enumerate(train_loader):\n",
    "    outputs = model(input_ids=batch[0].to(device), attention_mask=batch[1].to(device))\n",
    "    outputs = torch.argmax(outputs, axis = 1)\n",
    "    acc.append((outputs.cpu() == batch[2]).float().sum().numpy())\n",
    "    \n",
    "print(\"Accuracy: \", (sum(acc) / 5000) * 100, \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51a0e9fe-d012-413a-99cf-db46f7c03cba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Chintan",
   "language": "python",
   "name": "chintan"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
