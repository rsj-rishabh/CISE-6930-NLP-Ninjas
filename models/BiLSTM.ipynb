{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "import gensim\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import re,string,unicodedata\n",
        "\n",
        "from bs4 import BeautifulSoup\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from wordcloud import WordCloud,STOPWORDS\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "from gensim.utils import simple_preprocess \n",
        "from gensim.models import Phrases, Word2Vec\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "from nltk.tokenize import word_tokenize,sent_tokenize\n",
        "\n",
        "\n",
        "nltk.download('stopwords')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yd8D9Zb_vspT",
        "outputId": "e6fad11c-ccc6-4c92-b0de-74514e15dca1"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the IMDb dataset from the CSV file\n",
        "imdb_df = pd.read_csv('/imdb_dataset.csv', header=None, names=['review', 'sentiment'])\n",
        "imdb_df[\"sentiment\"] = np.where(imdb_df[\"sentiment\"] == \"positive\", 0, 1)\n",
        "\n",
        "gen_df = pd.read_csv('/gen_dataset.csv', header=None, names=['class', 'text'])\n",
        "gen_df = gen_df.append(pd.read_csv('/HYP-sarc-notsarc.csv'))\n",
        "gen_df = gen_df.append(pd.read_csv('/RQ-sarc-notsarc.csv'))\n",
        "\n",
        "gen_df[\"class\"] = np.where(gen_df[\"class\"] == \"notsarc\", 0, 1)\n",
        "\n",
        "stop = set(stopwords.words('english'))\n",
        "punctuation = list(string.punctuation)\n",
        "stop.update(punctuation)\n",
        "\n",
        "# Preprocess the dataset\n",
        "def strip_html(text):\n",
        "    soup = BeautifulSoup(text, \"html.parser\")\n",
        "    return soup.get_text()\n",
        "\n",
        "#Removing the square brackets\n",
        "def remove_between_square_brackets(text):\n",
        "    return re.sub('\\[[^]]*\\]', '', text)\n",
        "# Removing URL's\n",
        "def remove_between_square_brackets(text):\n",
        "    return re.sub(r'http\\S+', '', text)\n",
        "#Removing the stopwords from text\n",
        "def remove_stopwords(text):\n",
        "    final_text = []\n",
        "    for i in text.split():\n",
        "        if i.strip().lower() not in stop:\n",
        "            final_text.append(i.strip())\n",
        "    return \" \".join(final_text)\n",
        "#Removing the noisy text\n",
        "def denoise_text(text):\n",
        "    text = strip_html(text)\n",
        "    text = remove_between_square_brackets(text)\n",
        "    text = remove_stopwords(text)\n",
        "    return text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KmS_uZMhviOp",
        "outputId": "94894fcf-ff45-4929-a20c-20c0d277df03"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-4cc59efa8916>:6: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  gen_df = gen_df.append(pd.read_csv('/HYP-sarc-notsarc.csv'))\n",
            "<ipython-input-3-4cc59efa8916>:7: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  gen_df = gen_df.append(pd.read_csv('/RQ-sarc-notsarc.csv'))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "imdb_df['review']=imdb_df['review'].apply(denoise_text)\n",
        "gen_df['text']=gen_df['text'].apply(denoise_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yrm4JS6hwoqc",
        "outputId": "327ffa25-5f39-44f6-b5fc-e3d8a6c4e8f0"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-4cc59efa8916>:17: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
            "  soup = BeautifulSoup(text, \"html.parser\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "words, imdb_words, gen_words = [], [], []\n",
        "for i in imdb_df.review.values:\n",
        "    words.append(i.split())\n",
        "    imdb_words.append(i.split())\n",
        "words=words[1:]\n",
        "\n",
        "for i in gen_df.text.values:\n",
        "    words.append(i.split())\n",
        "    gen_words.append(i.split())"
      ],
      "metadata": {
        "id": "pp7HQIkewzF4"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "imdb_wv_model = Word2Vec(words, vector_size=500, window=3, min_count=1, workers=16)"
      ],
      "metadata": {
        "id": "0HwrOy-J29y2"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(imdb_wv_model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7RkjUghZ3ORS",
        "outputId": "e3761b3b-7ee2-4561-c6d1-2dcc65a29a78"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Word2Vec<vocab=485482, vector_size=500, alpha=0.025>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(words))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iPVUi1Nz7b4W",
        "outputId": "26c5dac4-921e-4d3e-fe72-defe2a8f2c9b"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "59387\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import keras\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "\n",
        "tokenizer = Tokenizer(485482)\n",
        "tokenizer.fit_on_texts(words)\n",
        "text = tokenizer.texts_to_sequences(words)\n",
        "text = keras.utils.pad_sequences(text, 75)\n",
        "\n",
        "print(text[:2])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L67LkbKU3PbY",
        "outputId": "c1df9136-9558-4b8e-f1d2-f67d85c1b432"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[   145    166  42448    703     75   1528   4516   2772   7673    703\n",
            "    7962    703 154647   1293   2081     17    355     37     99   3229\n",
            "    1655  11805     43   1401     95    159   1888   1562   1551  15623\n",
            "      79  11649    196   3075   2146   3154   2091  10361 154648   6038\n",
            "   15624   2956 105798   8723  15624    341    483     10    168     95\n",
            "      26  54856    604    823   8723    466   1376  33356    478    366\n",
            "    1051   2583   1376  54857     57  15623     84    247   3879   3815\n",
            "  154649     10   1237   4495   4324]\n",
            " [   201   2519    252   5587     86    369     26 154652    374   6640\n",
            "   45740     79 154653   2650   3700   5609    203      9  21813    913\n",
            "   11806   1916  14464  11483  33357     26    148     57  61470    345\n",
            "    2524   5587   4964    291      3     18  19547    172    389   2519\n",
            "       8    138    302     27  11650   1119   3719   2270    121    190\n",
            "    2027 105800   3857   1095   1080  21183    164   1799  18585    419\n",
            "      64   3416  27819  39661    675   7296   1340 154654 154655  39662\n",
            "      59  61471   1803     26   1459]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y = imdb_df[\"sentiment\"]"
      ],
      "metadata": {
        "id": "QJA50BEmCoWh"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "txt = tokenizer.texts_to_sequences(imdb_words)\n",
        "txt = keras.utils.pad_sequences(txt, 75)"
      ],
      "metadata": {
        "id": "RacOsXm2hZ1r"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(np.array(txt), np.array(y), train_size=0.8, stratify=y)"
      ],
      "metadata": {
        "id": "Qqh1HMzg4IP0"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = keras.models.Sequential([\n",
        "\n",
        "    # Embedding layer\n",
        "    keras.layers.Embedding(input_dim=len(imdb_wv_model.wv.key_to_index),\n",
        "                            output_dim=500,\n",
        "                            input_length=75,\n",
        "                            weights=[imdb_wv_model.wv.vectors],\n",
        "                            trainable=True),\n",
        "    \n",
        "    keras.layers.Dropout(0.2),\n",
        "\n",
        "    # BiLSTM layer\n",
        "    keras.layers.Bidirectional(keras.layers.LSTM(128, return_sequences=True)),\n",
        "\n",
        "    keras.layers.Bidirectional(keras.layers.LSTM(64)),\n",
        "\n",
        "    keras.layers.Dropout(0.2),\n",
        "\n",
        "    keras.layers.Dense(200),\n",
        "\n",
        "    keras.layers.Activation('relu'),\n",
        "\n",
        "    keras.layers.Dropout(0.2),\n",
        "    \n",
        "    # Output layer\n",
        "    keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model.summary()\n",
        "\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "model.fit(x_train, y_train, validation_data=(x_test, y_test), epochs=10, batch_size=64)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sSvtr3TQ14YU",
        "outputId": "c02f862d-953e-4f1d-8fa1-f85995af619b"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, 75, 500)           242741000 \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 75, 500)           0         \n",
            "                                                                 \n",
            " bidirectional (Bidirectiona  (None, 75, 256)          644096    \n",
            " l)                                                              \n",
            "                                                                 \n",
            " bidirectional_1 (Bidirectio  (None, 128)              164352    \n",
            " nal)                                                            \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 128)               0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 200)               25800     \n",
            "                                                                 \n",
            " activation (Activation)     (None, 200)               0         \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 200)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1)                 201       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 243,575,449\n",
            "Trainable params: 243,575,449\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "625/625 [==============================] - 121s 175ms/step - loss: 0.4550 - accuracy: 0.7571 - val_loss: 0.2928 - val_accuracy: 0.8743\n",
            "Epoch 2/10\n",
            "625/625 [==============================] - 60s 96ms/step - loss: 0.0820 - accuracy: 0.9705 - val_loss: 0.3564 - val_accuracy: 0.8541\n",
            "Epoch 3/10\n",
            "625/625 [==============================] - 52s 83ms/step - loss: 0.0020 - accuracy: 0.9995 - val_loss: 0.6538 - val_accuracy: 0.8479\n",
            "Epoch 4/10\n",
            "625/625 [==============================] - 51s 81ms/step - loss: 5.7097e-05 - accuracy: 1.0000 - val_loss: 0.8811 - val_accuracy: 0.8469\n",
            "Epoch 5/10\n",
            "625/625 [==============================] - 50s 80ms/step - loss: 1.0876e-05 - accuracy: 1.0000 - val_loss: 1.0206 - val_accuracy: 0.8471\n",
            "Epoch 6/10\n",
            "625/625 [==============================] - 48s 77ms/step - loss: 4.7240e-06 - accuracy: 1.0000 - val_loss: 1.0567 - val_accuracy: 0.8468\n",
            "Epoch 7/10\n",
            "625/625 [==============================] - 47s 76ms/step - loss: 3.2693e-06 - accuracy: 1.0000 - val_loss: 1.1977 - val_accuracy: 0.8463\n",
            "Epoch 8/10\n",
            "625/625 [==============================] - 47s 75ms/step - loss: 1.3973e-06 - accuracy: 1.0000 - val_loss: 1.2378 - val_accuracy: 0.8460\n",
            "Epoch 9/10\n",
            "625/625 [==============================] - 48s 77ms/step - loss: 9.1288e-07 - accuracy: 1.0000 - val_loss: 1.2960 - val_accuracy: 0.8458\n",
            "Epoch 10/10\n",
            "625/625 [==============================] - 47s 76ms/step - loss: 5.6970e-07 - accuracy: 1.0000 - val_loss: 1.3481 - val_accuracy: 0.8459\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7ff27a332c70>"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "txt2 = tokenizer.texts_to_sequences(gen_words)\n",
        "txt2 = keras.utils.pad_sequences(txt2, 75)\n",
        "\n",
        "y = gen_df[\"class\"]\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(np.array(txt2), np.array(y), train_size=0.8, stratify=y)\n",
        "\n",
        "model.fit(x_train, y_train, validation_data=(x_test, y_test), epochs=10)"
      ],
      "metadata": {
        "id": "K-q-Fpsl97A0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "80ede26a-1b25-45ce-d8c6-e69adb8eeaac"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "235/235 [==============================] - 52s 205ms/step - loss: 0.4346 - accuracy: 0.8446 - val_loss: 0.4154 - val_accuracy: 0.8472\n",
            "Epoch 2/10\n",
            "235/235 [==============================] - 33s 139ms/step - loss: 0.1924 - accuracy: 0.9268 - val_loss: 0.6372 - val_accuracy: 0.7417\n",
            "Epoch 3/10\n",
            "235/235 [==============================] - 26s 112ms/step - loss: 0.0583 - accuracy: 0.9839 - val_loss: 0.8033 - val_accuracy: 0.6560\n",
            "Epoch 4/10\n",
            "235/235 [==============================] - 23s 97ms/step - loss: 0.0308 - accuracy: 0.9883 - val_loss: 0.8491 - val_accuracy: 0.6693\n",
            "Epoch 5/10\n",
            "235/235 [==============================] - 20s 85ms/step - loss: 0.0241 - accuracy: 0.9876 - val_loss: 0.7779 - val_accuracy: 0.6448\n",
            "Epoch 6/10\n",
            "235/235 [==============================] - 19s 83ms/step - loss: 0.0160 - accuracy: 0.9901 - val_loss: 0.9308 - val_accuracy: 0.7460\n",
            "Epoch 7/10\n",
            "235/235 [==============================] - 20s 85ms/step - loss: 0.0155 - accuracy: 0.9907 - val_loss: 0.9061 - val_accuracy: 0.6763\n",
            "Epoch 8/10\n",
            "235/235 [==============================] - 19s 80ms/step - loss: 0.0134 - accuracy: 0.9916 - val_loss: 1.0738 - val_accuracy: 0.7220\n",
            "Epoch 9/10\n",
            "235/235 [==============================] - 18s 77ms/step - loss: 0.0132 - accuracy: 0.9916 - val_loss: 1.0176 - val_accuracy: 0.7135\n",
            "Epoch 10/10\n",
            "235/235 [==============================] - 18s 77ms/step - loss: 0.0138 - accuracy: 0.9903 - val_loss: 1.1323 - val_accuracy: 0.7274\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7ff1f0d80040>"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gen_wv_model = Word2Vec(gen_words, vector_size=500, window=3, min_count=1, workers=16)"
      ],
      "metadata": {
        "id": "JYfXu-htBH_e"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(gen_wv_model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-cf_G0T5BNyd",
        "outputId": "f84581c1-573a-4631-eca2-93d461fa8cb7"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Word2Vec<vocab=46908, vector_size=500, alpha=0.025>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# tokenizer = Tokenizer(46908)\n",
        "# tokenizer.fit_on_texts(gen_words)\n",
        "txt2 = tokenizer.texts_to_sequences(gen_words)\n",
        "txt2 = keras.utils.pad_sequences(txt2, 75)\n",
        "\n",
        "model = keras.models.Sequential([\n",
        "\n",
        "    # Embedding layer\n",
        "    keras.layers.Embedding(input_dim=len(imdb_wv_model.wv.key_to_index),\n",
        "                            output_dim=500,\n",
        "                            input_length=75,\n",
        "                            weights=[imdb_wv_model.wv.vectors],\n",
        "                            trainable=True),\n",
        "    \n",
        "    keras.layers.Dropout(0.2),\n",
        "\n",
        "    # BiLSTM layer\n",
        "    keras.layers.Bidirectional(keras.layers.LSTM(128, return_sequences=True)),\n",
        "\n",
        "    keras.layers.Bidirectional(keras.layers.LSTM(64)),\n",
        "\n",
        "    keras.layers.Dropout(0.2),\n",
        "\n",
        "    keras.layers.Dense(200),\n",
        "\n",
        "    keras.layers.Activation('relu'),\n",
        "\n",
        "    keras.layers.Dropout(0.2),\n",
        "    \n",
        "    # Output layer\n",
        "    keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "\n",
        "y = gen_df[\"class\"]\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(np.array(txt2), np.array(y), train_size=0.8, stratify=y, random_state=42)\n",
        "\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "model.fit(x_train, y_train, validation_data=(x_test, y_test), epochs=10, batch_size=64)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XKkAgrQOF-0I",
        "outputId": "433add0f-117f-4c9c-f13e-eb83b1e43303"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "118/118 [==============================] - 39s 260ms/step - loss: 0.4227 - accuracy: 0.8454 - val_loss: 0.4193 - val_accuracy: 0.8472\n",
            "Epoch 2/10\n",
            "118/118 [==============================] - 24s 206ms/step - loss: 0.4014 - accuracy: 0.8474 - val_loss: 0.4090 - val_accuracy: 0.8472\n",
            "Epoch 3/10\n",
            "118/118 [==============================] - 20s 170ms/step - loss: 0.2303 - accuracy: 0.9094 - val_loss: 0.6440 - val_accuracy: 0.7513\n",
            "Epoch 4/10\n",
            "118/118 [==============================] - 17s 144ms/step - loss: 0.0598 - accuracy: 0.9828 - val_loss: 0.7253 - val_accuracy: 0.7684\n",
            "Epoch 5/10\n",
            "118/118 [==============================] - 16s 136ms/step - loss: 0.0435 - accuracy: 0.9868 - val_loss: 0.6831 - val_accuracy: 0.7519\n",
            "Epoch 6/10\n",
            "118/118 [==============================] - 15s 121ms/step - loss: 0.0291 - accuracy: 0.9881 - val_loss: 0.8002 - val_accuracy: 0.7322\n",
            "Epoch 7/10\n",
            "118/118 [==============================] - 13s 112ms/step - loss: 0.0216 - accuracy: 0.9893 - val_loss: 0.7950 - val_accuracy: 0.6928\n",
            "Epoch 8/10\n",
            "118/118 [==============================] - 12s 99ms/step - loss: 0.0167 - accuracy: 0.9880 - val_loss: 0.9199 - val_accuracy: 0.7503\n",
            "Epoch 9/10\n",
            "118/118 [==============================] - 12s 99ms/step - loss: 0.0156 - accuracy: 0.9905 - val_loss: 0.8951 - val_accuracy: 0.6848\n",
            "Epoch 10/10\n",
            "118/118 [==============================] - 11s 94ms/step - loss: 0.0140 - accuracy: 0.9908 - val_loss: 0.8505 - val_accuracy: 0.6928\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7ff0a97979a0>"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zzCxsmZkAuoD"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}