{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "import gensim\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import re,string,unicodedata\n",
        "\n",
        "from bs4 import BeautifulSoup\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from wordcloud import WordCloud,STOPWORDS\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "from gensim.utils import simple_preprocess \n",
        "from gensim.models import Phrases, Word2Vec\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "from nltk.tokenize import word_tokenize,sent_tokenize\n",
        "\n",
        "\n",
        "nltk.download('stopwords')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yd8D9Zb_vspT",
        "outputId": "2d466d50-820c-4ed1-d111-a087345b2f37"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the IMDb dataset from the CSV file\n",
        "imdb_df = pd.read_csv('/irony-labeled.csv', header=None, names=['comment_text', 'label'])\n",
        "imdb_df[\"label\"] = np.where(imdb_df[\"label\"] == \"-1\", 1, 0)\n",
        "\n",
        "gen_df = pd.read_csv('/GEN-sarc-notsarc.csv', header=None, names=['class', 'text'])\n",
        "gen_df = gen_df.append(pd.read_csv('/HYP-sarc-notsarc.csv'))\n",
        "gen_df = gen_df.append(pd.read_csv('/RQ-sarc-notsarc.csv'))\n",
        "\n",
        "gen_df[\"class\"] = np.where(gen_df[\"class\"] == \"notsarc\", 0, 1)\n",
        "\n",
        "stop = set(stopwords.words('english'))\n",
        "punctuation = list(string.punctuation)\n",
        "stop.update(punctuation)\n",
        "\n",
        "# Preprocess the dataset\n",
        "def strip_html(text):\n",
        "    soup = BeautifulSoup(text, \"html.parser\")\n",
        "    return soup.get_text()\n",
        "\n",
        "#Removing the square brackets\n",
        "def remove_between_square_brackets(text):\n",
        "    return re.sub('\\[[^]]*\\]', '', text)\n",
        "# Removing URL's\n",
        "def remove_between_square_brackets(text):\n",
        "    return re.sub(r'http\\S+', '', text)\n",
        "#Removing the stopwords from text\n",
        "def remove_stopwords(text):\n",
        "    final_text = []\n",
        "    for i in text.split():\n",
        "        if i.strip().lower() not in stop:\n",
        "            final_text.append(i.strip())\n",
        "    return \" \".join(final_text)\n",
        "#Removing the noisy text\n",
        "def denoise_text(text):\n",
        "    text = strip_html(text)\n",
        "    text = remove_between_square_brackets(text)\n",
        "    text = remove_stopwords(text)\n",
        "    return text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KmS_uZMhviOp",
        "outputId": "fba0e73f-1c19-4045-8215-b21a49dbcaca"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-54c2b024cd1e>:6: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  gen_df = gen_df.append(pd.read_csv('/HYP-sarc-notsarc.csv'))\n",
            "<ipython-input-2-54c2b024cd1e>:7: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  gen_df = gen_df.append(pd.read_csv('/RQ-sarc-notsarc.csv'))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "imdb_df['comment_text']=imdb_df['comment_text'].apply(denoise_text)\n",
        "gen_df['text']=gen_df['text'].apply(denoise_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yrm4JS6hwoqc",
        "outputId": "a937e636-9909-4584-8003-a203d55e9913"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-54c2b024cd1e>:17: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
            "  soup = BeautifulSoup(text, \"html.parser\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "words, imdb_words, gen_words = [], [], []\n",
        "for i in imdb_df.comment_text.values:\n",
        "    words.append(i.split())\n",
        "    imdb_words.append(i.split())\n",
        "words=words[1:]\n",
        "\n",
        "for i in gen_df.text.values:\n",
        "    words.append(i.split())\n",
        "    gen_words.append(i.split())"
      ],
      "metadata": {
        "id": "pp7HQIkewzF4"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4KvgCffDwhfh",
        "outputId": "944050ab-a627-4cef-cadd-1050eea3111c"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "11336"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "imdb_wv_model = Word2Vec(words, vector_size=100, window=3, min_count=1, workers=16)"
      ],
      "metadata": {
        "id": "0HwrOy-J29y2"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(imdb_wv_model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7RkjUghZ3ORS",
        "outputId": "7b53131a-b16b-4666-ddaf-4e67dfc3c11c"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Word2Vec<vocab=53846, vector_size=100, alpha=0.025>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(words))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iPVUi1Nz7b4W",
        "outputId": "4d199d54-df65-464c-a205-b66551edefc2"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "11336\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import keras\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "\n",
        "tokenizer = Tokenizer(53846)\n",
        "tokenizer.fit_on_texts(words)\n",
        "text = tokenizer.texts_to_sequences(words)\n",
        "text = keras.utils.pad_sequences(text, 50)\n",
        "\n",
        "print(text[:2])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L67LkbKU3PbY",
        "outputId": "c2b97ad4-ca7d-4d92-c1ef-07f46cd8cc28"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[    0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0   840   610  7758  5688   668   192     3  5689    86\n",
            "    359  1035  4569 19649 19650 19651   100  2416  5058  1239  4570 19652\n",
            "    289     8  5690   777   206   668 12542   381  1688   175  2000   175\n",
            "    329   516]\n",
            " [  528   424 19653   134    26   757  1317  5059   841   117  2292   517\n",
            "    107  1450 19654  3540   669   311 19655  2293   710  1171   257  9557\n",
            "   2894     8 19656 19657     8  7759 12543 19658 19659  2293   710  2894\n",
            "   1567   378    64    76  5060    17  4571  9558    92    27  4158   469\n",
            "   6613  4571]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y = imdb_df[\"label\"]"
      ],
      "metadata": {
        "id": "QJA50BEmCoWh"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all(y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4NjH1pB2xg_f",
        "outputId": "06d27103-c8ee-4278-8dd7-30bdfe1be938"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "txt = tokenizer.texts_to_sequences(imdb_words)\n",
        "txt = keras.utils.pad_sequences(txt, 50)\n",
        "\n",
        "txt[:2]"
      ],
      "metadata": {
        "id": "RacOsXm2hZ1r",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "73d126be-83ea-431d-cf1e-daa94d439656"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[    0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0],\n",
              "       [    0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,   840,   610,  7758,\n",
              "         5688,   668,   192,     3,  5689,    86,   359,  1035,  4569,\n",
              "        19649, 19650, 19651,   100,  2416,  5058,  1239,  4570, 19652,\n",
              "          289,     8,  5690,   777,   206,   668, 12542,   381,  1688,\n",
              "          175,  2000,   175,   329,   516]], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(np.array(txt), np.array(y), train_size=0.8, stratify=y)"
      ],
      "metadata": {
        "id": "Qqh1HMzg4IP0"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "model = keras.models.Sequential([\n",
        "\n",
        "    keras.layers.Embedding(input_dim=len(imdb_wv_model.wv.key_to_index),\n",
        "                            output_dim=100,\n",
        "                            input_length=50,\n",
        "                            weights=[imdb_wv_model.wv.vectors],\n",
        "                            trainable=True),\n",
        "    keras.layers.Dropout(0.3),\n",
        "    keras.layers.Conv1D(50, 3, activation='relu', padding='same', strides=1),\n",
        "    keras.layers.MaxPool1D(2),\n",
        "    keras.layers.Dropout(0.3),\n",
        "    keras.layers.Flatten(),\n",
        "    keras.layers.Dense(10),\n",
        "    keras.layers.Dropout(0.2),\n",
        "    keras.layers.Activation('relu'),\n",
        "    keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model.summary()\n",
        "\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy', keras.metrics.Precision(), keras.metrics.Recall()])\n",
        "\n",
        "model.fit(x_train, y_train, validation_data=(x_test, y_test), epochs=10, batch_size=64)\n",
        "\n",
        "txt2 = tokenizer.texts_to_sequences(gen_words)\n",
        "txt2 = keras.utils.pad_sequences(txt2, 50)\n",
        "\n",
        "y = gen_df[\"class\"]\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(np.array(txt2), np.array(y), train_size=0.8, stratify=y)\n",
        "\n",
        "model.fit(x_train, y_train, validation_data=(x_test, y_test), epochs=10)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sSvtr3TQ14YU",
        "outputId": "2662dac2-0150-4d2d-9224-9a2c7b2dde41"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_15\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_15 (Embedding)    (None, 50, 100)           5384600   \n",
            "                                                                 \n",
            " dropout_42 (Dropout)        (None, 50, 100)           0         \n",
            "                                                                 \n",
            " conv1d_15 (Conv1D)          (None, 50, 50)            15050     \n",
            "                                                                 \n",
            " max_pooling1d_15 (MaxPoolin  (None, 25, 50)           0         \n",
            " g1D)                                                            \n",
            "                                                                 \n",
            " dropout_43 (Dropout)        (None, 25, 50)            0         \n",
            "                                                                 \n",
            " flatten_11 (Flatten)        (None, 1250)              0         \n",
            "                                                                 \n",
            " dense_30 (Dense)            (None, 10)                12510     \n",
            "                                                                 \n",
            " dropout_44 (Dropout)        (None, 10)                0         \n",
            "                                                                 \n",
            " activation_15 (Activation)  (None, 10)                0         \n",
            "                                                                 \n",
            " dense_31 (Dense)            (None, 1)                 11        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5,412,171\n",
            "Trainable params: 5,412,171\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "25/25 [==============================] - 5s 162ms/step - loss: 0.6458 - accuracy: 0.6955 - precision_15: 0.7197 - recall_15: 0.9496 - val_loss: 0.6136 - val_accuracy: 0.7231 - val_precision_15: 0.7231 - val_recall_15: 1.0000\n",
            "Epoch 2/10\n",
            "25/25 [==============================] - 3s 133ms/step - loss: 0.6221 - accuracy: 0.7244 - precision_15: 0.7244 - recall_15: 1.0000 - val_loss: 0.6105 - val_accuracy: 0.7231 - val_precision_15: 0.7231 - val_recall_15: 1.0000\n",
            "Epoch 3/10\n",
            "25/25 [==============================] - 3s 136ms/step - loss: 0.5930 - accuracy: 0.7250 - precision_15: 0.7248 - recall_15: 1.0000 - val_loss: 0.6014 - val_accuracy: 0.7231 - val_precision_15: 0.7231 - val_recall_15: 1.0000\n",
            "Epoch 4/10\n",
            "25/25 [==============================] - 3s 107ms/step - loss: 0.5819 - accuracy: 0.7237 - precision_15: 0.7245 - recall_15: 0.9982 - val_loss: 0.5988 - val_accuracy: 0.7231 - val_precision_15: 0.7231 - val_recall_15: 1.0000\n",
            "Epoch 5/10\n",
            "25/25 [==============================] - 3s 114ms/step - loss: 0.5781 - accuracy: 0.7244 - precision_15: 0.7244 - recall_15: 1.0000 - val_loss: 0.5927 - val_accuracy: 0.7231 - val_precision_15: 0.7231 - val_recall_15: 1.0000\n",
            "Epoch 6/10\n",
            "25/25 [==============================] - 2s 78ms/step - loss: 0.5733 - accuracy: 0.7244 - precision_15: 0.7244 - recall_15: 1.0000 - val_loss: 0.5913 - val_accuracy: 0.7231 - val_precision_15: 0.7231 - val_recall_15: 1.0000\n",
            "Epoch 7/10\n",
            "25/25 [==============================] - 3s 117ms/step - loss: 0.5543 - accuracy: 0.7244 - precision_15: 0.7244 - recall_15: 1.0000 - val_loss: 0.5848 - val_accuracy: 0.7231 - val_precision_15: 0.7231 - val_recall_15: 1.0000\n",
            "Epoch 8/10\n",
            "25/25 [==============================] - 3s 98ms/step - loss: 0.5423 - accuracy: 0.7244 - precision_15: 0.7244 - recall_15: 1.0000 - val_loss: 0.5816 - val_accuracy: 0.7231 - val_precision_15: 0.7231 - val_recall_15: 1.0000\n",
            "Epoch 9/10\n",
            "25/25 [==============================] - 3s 105ms/step - loss: 0.5181 - accuracy: 0.7256 - precision_15: 0.7253 - recall_15: 1.0000 - val_loss: 0.5765 - val_accuracy: 0.7231 - val_precision_15: 0.7231 - val_recall_15: 1.0000\n",
            "Epoch 10/10\n",
            "25/25 [==============================] - 2s 94ms/step - loss: 0.4820 - accuracy: 0.7244 - precision_15: 0.7244 - recall_15: 1.0000 - val_loss: 0.5718 - val_accuracy: 0.7231 - val_precision_15: 0.7231 - val_recall_15: 1.0000\n",
            "Epoch 1/10\n",
            "235/235 [==============================] - 24s 104ms/step - loss: 0.4424 - accuracy: 0.8474 - precision_15: 0.8474 - recall_15: 1.0000 - val_loss: 0.4388 - val_accuracy: 0.8472 - val_precision_15: 0.8472 - val_recall_15: 1.0000\n",
            "Epoch 2/10\n",
            "235/235 [==============================] - 10s 45ms/step - loss: 0.3473 - accuracy: 0.8474 - precision_15: 0.8474 - recall_15: 1.0000 - val_loss: 0.4355 - val_accuracy: 0.8472 - val_precision_15: 0.8472 - val_recall_15: 1.0000\n",
            "Epoch 3/10\n",
            "235/235 [==============================] - 6s 25ms/step - loss: 0.1916 - accuracy: 0.9082 - precision_15: 0.9179 - recall_15: 0.9793 - val_loss: 0.5849 - val_accuracy: 0.7939 - val_precision_15: 0.8684 - val_recall_15: 0.8919\n",
            "Epoch 4/10\n",
            "235/235 [==============================] - 5s 21ms/step - loss: 0.0891 - accuracy: 0.9659 - precision_15: 0.9788 - recall_15: 0.9810 - val_loss: 0.8177 - val_accuracy: 0.7827 - val_precision_15: 0.8605 - val_recall_15: 0.8875\n",
            "Epoch 5/10\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.0637 - accuracy: 0.9783 - precision_15: 0.9877 - recall_15: 0.9866 - val_loss: 0.8553 - val_accuracy: 0.7188 - val_precision_15: 0.8714 - val_recall_15: 0.7838\n",
            "Epoch 6/10\n",
            "235/235 [==============================] - 2s 10ms/step - loss: 0.0528 - accuracy: 0.9808 - precision_15: 0.9905 - recall_15: 0.9868 - val_loss: 0.9266 - val_accuracy: 0.7945 - val_precision_15: 0.8606 - val_recall_15: 0.9038\n",
            "Epoch 7/10\n",
            "235/235 [==============================] - 3s 11ms/step - loss: 0.0476 - accuracy: 0.9827 - precision_15: 0.9915 - recall_15: 0.9881 - val_loss: 0.9171 - val_accuracy: 0.7705 - val_precision_15: 0.8694 - val_recall_15: 0.8580\n",
            "Epoch 8/10\n",
            "235/235 [==============================] - 2s 10ms/step - loss: 0.0365 - accuracy: 0.9854 - precision_15: 0.9924 - recall_15: 0.9903 - val_loss: 0.9869 - val_accuracy: 0.7785 - val_precision_15: 0.8697 - val_recall_15: 0.8686\n",
            "Epoch 9/10\n",
            "235/235 [==============================] - 2s 10ms/step - loss: 0.0353 - accuracy: 0.9861 - precision_15: 0.9940 - recall_15: 0.9896 - val_loss: 1.0327 - val_accuracy: 0.7849 - val_precision_15: 0.8652 - val_recall_15: 0.8837\n",
            "Epoch 10/10\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 0.0317 - accuracy: 0.9854 - precision_15: 0.9924 - recall_15: 0.9903 - val_loss: 1.0532 - val_accuracy: 0.7822 - val_precision_15: 0.8662 - val_recall_15: 0.8787\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f04316364c0>"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "val_recall = 0.8662 *100\n",
        "val_precision = 0.8787 *100\n",
        "val_f1 = (2 * val_precision * val_recall) / (val_precision + val_recall)\n",
        "\n",
        "val_f1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iP0PzAn7krA9",
        "outputId": "9f8a93a8-2476-46d3-8f62-ad96ff90355f"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "87.24052266605536"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save(\"/cnn-irony.h\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pfxrQD7Xl-cc",
        "outputId": "50aa7899-065b-4928-bf02-478f2025ca3c"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gen_wv_model = Word2Vec(gen_words, vector_size=100, window=3, min_count=1, workers=16)"
      ],
      "metadata": {
        "id": "JYfXu-htBH_e"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(gen_wv_model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-cf_G0T5BNyd",
        "outputId": "81ed82c0-1309-459e-857d-be7552c9d40b"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Word2Vec<vocab=46908, vector_size=100, alpha=0.025>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# tokenizer = Tokenizer(46908)\n",
        "# tokenizer.fit_on_texts(gen_words)\n",
        "txt2 = tokenizer.texts_to_sequences(gen_words)\n",
        "txt2 = keras.utils.pad_sequences(txt2, 50)\n",
        "\n",
        "model = keras.models.Sequential([\n",
        "\n",
        "    # Embedding layer\n",
        "    keras.layers.Embedding(input_dim=len(imdb_wv_model.wv.key_to_index),\n",
        "                            output_dim=100,\n",
        "                            input_length=50,\n",
        "                            weights=[imdb_wv_model.wv.vectors],\n",
        "                            trainable=True),\n",
        "    keras.layers.Dropout(0.3),\n",
        "    keras.layers.Conv1D(50, 3, activation='relu', padding='same', strides=1),\n",
        "    keras.layers.MaxPool1D(2),\n",
        "    keras.layers.Dropout(0.3),\n",
        "    keras.layers.Flatten(),\n",
        "    keras.layers.Dense(10),\n",
        "    keras.layers.Dropout(0.2),\n",
        "    keras.layers.Activation('relu'),\n",
        "    keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "\n",
        "y = gen_df[\"class\"]\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(np.array(txt2), np.array(y), train_size=0.8, stratify=y, random_state=42)\n",
        "\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy', keras.metrics.Precision(), keras.metrics.Recall()])\n",
        "\n",
        "model.fit(x_train, y_train, validation_data=(x_test, y_test), epochs=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XKkAgrQOF-0I",
        "outputId": "ae886497-192b-4fb5-f0ba-850debf347e6"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "235/235 [==============================] - 26s 104ms/step - loss: 0.4497 - accuracy: 0.8458 - precision_17: 0.8477 - recall_17: 0.9972 - val_loss: 0.4421 - val_accuracy: 0.8472 - val_precision_17: 0.8472 - val_recall_17: 1.0000\n",
            "Epoch 2/10\n",
            "235/235 [==============================] - 11s 46ms/step - loss: 0.4351 - accuracy: 0.8474 - precision_17: 0.8474 - recall_17: 1.0000 - val_loss: 0.4166 - val_accuracy: 0.8472 - val_precision_17: 0.8472 - val_recall_17: 1.0000\n",
            "Epoch 3/10\n",
            "235/235 [==============================] - 6s 27ms/step - loss: 0.4118 - accuracy: 0.8474 - precision_17: 0.8474 - recall_17: 1.0000 - val_loss: 0.4148 - val_accuracy: 0.8472 - val_precision_17: 0.8472 - val_recall_17: 1.0000\n",
            "Epoch 4/10\n",
            "235/235 [==============================] - 5s 22ms/step - loss: 0.3251 - accuracy: 0.8551 - precision_17: 0.8555 - recall_17: 0.9975 - val_loss: 0.4320 - val_accuracy: 0.8387 - val_precision_17: 0.8474 - val_recall_17: 0.9874\n",
            "Epoch 5/10\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.1391 - accuracy: 0.9447 - precision_17: 0.9527 - recall_17: 0.9837 - val_loss: 0.5605 - val_accuracy: 0.8120 - val_precision_17: 0.8607 - val_recall_17: 0.9283\n",
            "Epoch 6/10\n",
            "235/235 [==============================] - 2s 10ms/step - loss: 0.0665 - accuracy: 0.9774 - precision_17: 0.9841 - recall_17: 0.9893 - val_loss: 0.6987 - val_accuracy: 0.7891 - val_precision_17: 0.8691 - val_recall_17: 0.8843\n",
            "Epoch 7/10\n",
            "235/235 [==============================] - 3s 11ms/step - loss: 0.0524 - accuracy: 0.9806 - precision_17: 0.9870 - recall_17: 0.9901 - val_loss: 0.8434 - val_accuracy: 0.8206 - val_precision_17: 0.8546 - val_recall_17: 0.9497\n",
            "Epoch 8/10\n",
            "235/235 [==============================] - 2s 9ms/step - loss: 0.0445 - accuracy: 0.9832 - precision_17: 0.9887 - recall_17: 0.9915 - val_loss: 0.8188 - val_accuracy: 0.7822 - val_precision_17: 0.8675 - val_recall_17: 0.8768\n",
            "Epoch 9/10\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 0.0430 - accuracy: 0.9858 - precision_17: 0.9921 - recall_17: 0.9910 - val_loss: 0.7891 - val_accuracy: 0.7742 - val_precision_17: 0.8700 - val_recall_17: 0.8624\n",
            "Epoch 10/10\n",
            "235/235 [==============================] - 2s 9ms/step - loss: 0.0345 - accuracy: 0.9884 - precision_17: 0.9932 - recall_17: 0.9931 - val_loss: 0.8724 - val_accuracy: 0.7449 - val_precision_17: 0.8752 - val_recall_17: 0.8152\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f03f1df7310>"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "val_recall = 0.8752 *100\n",
        "val_precision = 0.8152 *100\n",
        "val_f1 = (2 * val_precision * val_recall) / (val_precision + val_recall)\n",
        "\n",
        "val_f1"
      ],
      "metadata": {
        "id": "zzCxsmZkAuoD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "713d6489-d7c7-4127-fc42-f42d957c5d3e"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "84.41351632749645"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r \"/bilstm.zip\" \"/bert-with-intermediate-task.h\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "llUwZ02NtfpW",
        "outputId": "c380ba45-0100-4957-9157-e8f186db2d37"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: bert-with-intermediate-task.h/ (stored 0%)\n",
            "  adding: bert-with-intermediate-task.h/assets/ (stored 0%)\n",
            "  adding: bert-with-intermediate-task.h/keras_metadata.pb (deflated 92%)\n",
            "  adding: bert-with-intermediate-task.h/variables/ (stored 0%)\n",
            "  adding: bert-with-intermediate-task.h/variables/variables.index (deflated 67%)\n",
            "  adding: bert-with-intermediate-task.h/variables/variables.data-00000-of-00001 (deflated 48%)\n",
            "  adding: bert-with-intermediate-task.h/fingerprint.pb (stored 0%)\n",
            "  adding: bert-with-intermediate-task.h/saved_model.pb (deflated 90%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ehjAu4Urt4zE"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}