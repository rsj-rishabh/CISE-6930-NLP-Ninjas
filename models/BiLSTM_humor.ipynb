{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "import gensim\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import re,string,unicodedata\n",
        "\n",
        "from bs4 import BeautifulSoup\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from wordcloud import WordCloud,STOPWORDS\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "from gensim.utils import simple_preprocess \n",
        "from gensim.models import Phrases, Word2Vec\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "from nltk.tokenize import word_tokenize,sent_tokenize\n",
        "\n",
        "\n",
        "nltk.download('stopwords')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yd8D9Zb_vspT",
        "outputId": "7cc88a7c-6320-42fa-8dda-a74fed638022"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the IMDb dataset from the CSV file\n",
        "imdb_df = pd.read_csv('/content/dataset.csv', header=None, names=['text', 'humor'])\n",
        "print(imdb_df.head())\n",
        "\n",
        "print(imdb_df[\"humor\"].unique())\n",
        "\n",
        "imdb_df[\"humor\"] = np.where(imdb_df[\"humor\"] == 'False', 0, 1)\n",
        "print(imdb_df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6kc-Dp6D4KR-",
        "outputId": "01406d4d-14a3-4f7c-b59c-0bfaedbb5e1b"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                                text  humor\n",
            "0                                               text  humor\n",
            "1  Joe biden rules out 2020 bid: 'guys, i'm not r...  False\n",
            "2  Watch: darvish gave hitter whiplash with slow ...  False\n",
            "3  What do you call a turtle without its shell? d...   True\n",
            "4      5 reasons the 2016 election feels so personal  False\n",
            "['humor' 'False' 'True']\n",
            "                                                text  humor\n",
            "0                                               text      1\n",
            "1  Joe biden rules out 2020 bid: 'guys, i'm not r...      0\n",
            "2  Watch: darvish gave hitter whiplash with slow ...      0\n",
            "3  What do you call a turtle without its shell? d...      1\n",
            "4      5 reasons the 2016 election feels so personal      0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gen_df = pd.read_csv('/content/GEN-sarc-notsarc.csv', header=None, names=['class', 'text'])\n",
        "gen_df = gen_df.append(pd.read_csv('/content/HYP-sarc-notsarc.csv'))\n",
        "gen_df = gen_df.append(pd.read_csv('/content/RQ-sarc-notsarc.csv'))\n",
        "\n",
        "gen_df[\"class\"] = np.where(gen_df[\"class\"] == \"notsarc\", 0, 1)\n",
        "\n",
        "stop = set(stopwords.words('english'))\n",
        "punctuation = list(string.punctuation)\n",
        "stop.update(punctuation)\n",
        "\n",
        "# Preprocess the dataset\n",
        "def strip_html(text):\n",
        "    soup = BeautifulSoup(text, \"html.parser\")\n",
        "    return soup.get_text()\n",
        "\n",
        "#Removing the square brackets\n",
        "def remove_between_square_brackets(text):\n",
        "    return re.sub('\\[[^]]*\\]', '', text)\n",
        "# Removing URL's\n",
        "def remove_between_square_brackets(text):\n",
        "    return re.sub(r'http\\S+', '', text)\n",
        "#Removing the stopwords from text\n",
        "def remove_stopwords(text):\n",
        "    final_text = []\n",
        "    for i in text.split():\n",
        "        if i.strip().lower() not in stop:\n",
        "            final_text.append(i.strip())\n",
        "    return \" \".join(final_text)\n",
        "#Removing the noisy text\n",
        "def denoise_text(text):\n",
        "    text = strip_html(text)\n",
        "    text = remove_between_square_brackets(text)\n",
        "    text = remove_stopwords(text)\n",
        "    return text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KmS_uZMhviOp",
        "outputId": "632143b0-de7c-4606-8b8e-b38ccf54f22a"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-30-e5a98f61f389>:2: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  gen_df = gen_df.append(pd.read_csv('/content/HYP-sarc-notsarc.csv'))\n",
            "<ipython-input-30-e5a98f61f389>:3: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  gen_df = gen_df.append(pd.read_csv('/content/RQ-sarc-notsarc.csv'))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "imdb_df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "PJnMxbsF3ESu",
        "outputId": "a7c629a6-c87e-4b38-9d1a-6f5c2da6b093"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                text  humor\n",
              "0                                               text      1\n",
              "1  Joe biden rules out 2020 bid: 'guys, i'm not r...      0\n",
              "2  Watch: darvish gave hitter whiplash with slow ...      0\n",
              "3  What do you call a turtle without its shell? d...      1\n",
              "4      5 reasons the 2016 election feels so personal      0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-3e060ac0-d76a-4d85-a6c4-64d62175b31b\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>humor</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>text</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Joe biden rules out 2020 bid: 'guys, i'm not r...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Watch: darvish gave hitter whiplash with slow ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>What do you call a turtle without its shell? d...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5 reasons the 2016 election feels so personal</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3e060ac0-d76a-4d85-a6c4-64d62175b31b')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-3e060ac0-d76a-4d85-a6c4-64d62175b31b button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-3e060ac0-d76a-4d85-a6c4-64d62175b31b');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "imdb_df['text']=imdb_df['text'].apply(denoise_text)\n",
        "gen_df['text']=gen_df['text'].apply(denoise_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yrm4JS6hwoqc",
        "outputId": "b20eb301-53dc-4966-f7ce-b98ef61df451"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-30-e5a98f61f389>:13: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
            "  soup = BeautifulSoup(text, \"html.parser\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "words, imdb_words, gen_words = [], [], []\n",
        "for i in imdb_df.text.values:\n",
        "    words.append(i.split())\n",
        "    imdb_words.append(i.split())\n",
        "words=words[1:]\n",
        "\n",
        "for i in gen_df.text.values:\n",
        "    words.append(i.split())\n",
        "    gen_words.append(i.split())"
      ],
      "metadata": {
        "id": "pp7HQIkewzF4"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4KvgCffDwhfh",
        "outputId": "ff78de3a-a58b-4968-e15d-8921758b147d"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "209387"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "imdb_wv_model = Word2Vec(words, vector_size=500, window=3, min_count=1, workers=16)"
      ],
      "metadata": {
        "id": "0HwrOy-J29y2"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(imdb_wv_model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7RkjUghZ3ORS",
        "outputId": "bad0b4ff-d0c8-4e82-bd31-cee83b55643c"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Word2Vec<vocab=178665, vector_size=500, alpha=0.025>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(words))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iPVUi1Nz7b4W",
        "outputId": "f2146365-9ad9-49cf-fbff-816ea3ab4e36"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "209387\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import keras\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "\n",
        "tokenizer = Tokenizer(178665)\n",
        "tokenizer.fit_on_texts(words)\n",
        "text = tokenizer.texts_to_sequences(words)\n",
        "text = keras.utils.pad_sequences(text, 50)\n",
        "\n",
        "print(text[:5])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L67LkbKU3PbY",
        "outputId": "8f3fce8e-ba52-4e97-adf6-3bc4b4b8c410"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[    0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0   916  1884   636  3927 69516 69517\n",
            "      8 48343]\n",
            " [    0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0   985 69518   440 32225 48344\n",
            "   1187  4433]\n",
            " [    0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     2  4502   108\n",
            "  27962  1913]\n",
            " [    0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0    53   342   492   314\n",
            "   1546   720]\n",
            " [    0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0 69519   111   470   278  6676 32226     5\n",
            "   9812   179]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y = imdb_df[\"humor\"]"
      ],
      "metadata": {
        "id": "QJA50BEmCoWh"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all(y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4NjH1pB2xg_f",
        "outputId": "264d2eec-2f99-4141-9a42-8b31c66af671"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y[:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pA53ZgzT2p74",
        "outputId": "01093531-e182-4ae8-ec2a-b3ded5e8ed38"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    1\n",
              "1    0\n",
              "2    0\n",
              "3    1\n",
              "4    0\n",
              "Name: humor, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "txt = tokenizer.texts_to_sequences(imdb_words)\n",
        "txt = keras.utils.pad_sequences(txt, 50)\n",
        "\n",
        "txt[:2]"
      ],
      "metadata": {
        "id": "RacOsXm2hZ1r",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b13f07ab-bd13-461a-d9f6-959c717fc283"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[    0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,  1422],\n",
              "       [    0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,   916,  1884,   636,\n",
              "         3927, 69516, 69517,     8, 48343]], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(np.array(txt), np.array(y), train_size=0.8, stratify=y)"
      ],
      "metadata": {
        "id": "Qqh1HMzg4IP0"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "model = keras.models.Sequential([\n",
        "\n",
        "    # Embedding layer\n",
        "    keras.layers.Embedding(input_dim=len(imdb_wv_model.wv.key_to_index),\n",
        "                            output_dim=500,\n",
        "                            input_length=50,\n",
        "                            weights=[imdb_wv_model.wv.vectors],\n",
        "                            trainable=True),\n",
        "    \n",
        "    keras.layers.Dropout(0.2),\n",
        "\n",
        "    # BiLSTM layer\n",
        "    keras.layers.Bidirectional(keras.layers.LSTM(128, return_sequences=True)),\n",
        "\n",
        "    keras.layers.Bidirectional(keras.layers.LSTM(64)),\n",
        "\n",
        "    keras.layers.Dropout(0.2),\n",
        "\n",
        "    keras.layers.Dense(200),\n",
        "\n",
        "    keras.layers.Activation('relu'),\n",
        "\n",
        "    keras.layers.Dropout(0.2),\n",
        "    \n",
        "    # Output layer\n",
        "    keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model.summary()\n",
        "\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy', keras.metrics.Precision(), keras.metrics.Recall()])\n",
        "\n",
        "model.fit(x_train, y_train, validation_data=(x_test, y_test), epochs=10, batch_size=64)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sSvtr3TQ14YU",
        "outputId": "18b45522-351b-4707-9783-6aa6d1f105fc"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, 50, 500)           89332500  \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 50, 500)           0         \n",
            "                                                                 \n",
            " bidirectional (Bidirectiona  (None, 50, 256)          644096    \n",
            " l)                                                              \n",
            "                                                                 \n",
            " bidirectional_1 (Bidirectio  (None, 128)              164352    \n",
            " nal)                                                            \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 128)               0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 200)               25800     \n",
            "                                                                 \n",
            " activation (Activation)     (None, 200)               0         \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 200)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1)                 201       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 90,166,949\n",
            "Trainable params: 90,166,949\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "2500/2500 [==============================] - 126s 45ms/step - loss: 0.1800 - accuracy: 0.9245 - precision: 0.9243 - recall: 0.9246 - val_loss: 0.1209 - val_accuracy: 0.9545 - val_precision: 0.9684 - val_recall: 0.9397\n",
            "Epoch 2/10\n",
            "2500/2500 [==============================] - 94s 38ms/step - loss: 0.0393 - accuracy: 0.9861 - precision: 0.9865 - recall: 0.9856 - val_loss: 0.1428 - val_accuracy: 0.9495 - val_precision: 0.9588 - val_recall: 0.9395\n",
            "Epoch 3/10\n",
            "2500/2500 [==============================] - 92s 37ms/step - loss: 0.0147 - accuracy: 0.9949 - precision: 0.9954 - recall: 0.9944 - val_loss: 0.1888 - val_accuracy: 0.9475 - val_precision: 0.9455 - val_recall: 0.9497\n",
            "Epoch 4/10\n",
            "2500/2500 [==============================] - 90s 36ms/step - loss: 0.0073 - accuracy: 0.9974 - precision: 0.9976 - recall: 0.9972 - val_loss: 0.2665 - val_accuracy: 0.9437 - val_precision: 0.9417 - val_recall: 0.9461\n",
            "Epoch 5/10\n",
            "2500/2500 [==============================] - 93s 37ms/step - loss: 0.0046 - accuracy: 0.9984 - precision: 0.9985 - recall: 0.9983 - val_loss: 0.3065 - val_accuracy: 0.9426 - val_precision: 0.9369 - val_recall: 0.9491\n",
            "Epoch 6/10\n",
            "2500/2500 [==============================] - 91s 37ms/step - loss: 0.0030 - accuracy: 0.9990 - precision: 0.9991 - recall: 0.9989 - val_loss: 0.3602 - val_accuracy: 0.9390 - val_precision: 0.9552 - val_recall: 0.9212\n",
            "Epoch 7/10\n",
            "2500/2500 [==============================] - 91s 36ms/step - loss: 0.0016 - accuracy: 0.9994 - precision: 0.9995 - recall: 0.9994 - val_loss: 0.5472 - val_accuracy: 0.9398 - val_precision: 0.9388 - val_recall: 0.9408\n",
            "Epoch 8/10\n",
            "2500/2500 [==============================] - 90s 36ms/step - loss: 0.0015 - accuracy: 0.9995 - precision: 0.9996 - recall: 0.9994 - val_loss: 0.4581 - val_accuracy: 0.9332 - val_precision: 0.9299 - val_recall: 0.9370\n",
            "Epoch 9/10\n",
            "2500/2500 [==============================] - 90s 36ms/step - loss: 0.0012 - accuracy: 0.9996 - precision: 0.9997 - recall: 0.9996 - val_loss: 0.5258 - val_accuracy: 0.9367 - val_precision: 0.9462 - val_recall: 0.9261\n",
            "Epoch 10/10\n",
            "2500/2500 [==============================] - 89s 36ms/step - loss: 9.0040e-04 - accuracy: 0.9997 - precision: 0.9997 - recall: 0.9997 - val_loss: 0.4855 - val_accuracy: 0.9350 - val_precision: 0.9289 - val_recall: 0.9421\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f0915c2bf70>"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "val_recall = 0.8160\n",
        "val_precision = 0.8572\n",
        "val_f1 = (2 * val_precision * val_recall) / (val_precision + val_recall)\n",
        "\n",
        "val_f1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7YcCleAvkJ4s",
        "outputId": "cbdff001-3b26-4d8e-cfae-1c1892773e0c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8360927563949319"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "txt2 = tokenizer.texts_to_sequences(gen_words)\n",
        "txt2 = keras.utils.pad_sequences(txt2, 50)\n",
        "\n",
        "y = gen_df[\"class\"]\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(np.array(txt2), np.array(y), train_size=0.8, stratify=y)\n",
        "\n",
        "model.fit(x_train, y_train, validation_data=(x_test, y_test), epochs=10)"
      ],
      "metadata": {
        "id": "K-q-Fpsl97A0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "54dd60b3-f142-4353-b2f2-e40755f67076"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "235/235 [==============================] - 41s 159ms/step - loss: 0.4683 - accuracy: 0.8442 - precision: 0.8476 - recall: 0.9950 - val_loss: 0.4066 - val_accuracy: 0.8472 - val_precision: 0.8472 - val_recall: 1.0000\n",
            "Epoch 2/10\n",
            "235/235 [==============================] - 20s 84ms/step - loss: 0.2552 - accuracy: 0.8992 - precision: 0.9131 - recall: 0.9738 - val_loss: 0.5582 - val_accuracy: 0.7481 - val_precision: 0.8678 - val_recall: 0.8290\n",
            "Epoch 3/10\n",
            "235/235 [==============================] - 15s 61ms/step - loss: 0.0833 - accuracy: 0.9730 - precision: 0.9840 - recall: 0.9841 - val_loss: 0.6831 - val_accuracy: 0.7322 - val_precision: 0.8632 - val_recall: 0.8127\n",
            "Epoch 4/10\n",
            "235/235 [==============================] - 11s 48ms/step - loss: 0.0460 - accuracy: 0.9851 - precision: 0.9942 - recall: 0.9882 - val_loss: 0.7998 - val_accuracy: 0.7567 - val_precision: 0.8584 - val_recall: 0.8536\n",
            "Epoch 5/10\n",
            "235/235 [==============================] - 10s 41ms/step - loss: 0.0352 - accuracy: 0.9854 - precision: 0.9942 - recall: 0.9885 - val_loss: 0.8180 - val_accuracy: 0.7306 - val_precision: 0.8614 - val_recall: 0.8127\n",
            "Epoch 6/10\n",
            "235/235 [==============================] - 10s 42ms/step - loss: 0.0242 - accuracy: 0.9863 - precision: 0.9932 - recall: 0.9906 - val_loss: 0.8614 - val_accuracy: 0.7577 - val_precision: 0.8636 - val_recall: 0.8479\n",
            "Epoch 7/10\n",
            "235/235 [==============================] - 10s 41ms/step - loss: 0.0223 - accuracy: 0.9880 - precision: 0.9950 - recall: 0.9909 - val_loss: 0.8578 - val_accuracy: 0.7599 - val_precision: 0.8594 - val_recall: 0.8567\n",
            "Epoch 8/10\n",
            "235/235 [==============================] - 9s 40ms/step - loss: 0.0186 - accuracy: 0.9879 - precision: 0.9949 - recall: 0.9907 - val_loss: 1.0127 - val_accuracy: 0.7593 - val_precision: 0.8593 - val_recall: 0.8561\n",
            "Epoch 9/10\n",
            "235/235 [==============================] - 10s 41ms/step - loss: 0.0171 - accuracy: 0.9869 - precision: 0.9934 - recall: 0.9912 - val_loss: 1.0257 - val_accuracy: 0.7769 - val_precision: 0.8564 - val_recall: 0.8850\n",
            "Epoch 10/10\n",
            "235/235 [==============================] - 9s 39ms/step - loss: 0.0166 - accuracy: 0.9883 - precision: 0.9939 - recall: 0.9923 - val_loss: 1.1012 - val_accuracy: 0.7380 - val_precision: 0.8646 - val_recall: 0.8190\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f098ae282b0>"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "val_recall = 0.8646 *100\n",
        "val_precision = 0.8190 *100\n",
        "val_f1 = (2 * val_precision * val_recall) / (val_precision + val_recall)\n",
        "\n",
        "val_f1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iP0PzAn7krA9",
        "outputId": "547d6bb8-7f11-4dd4-9af2-eda7509ddf64"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "84.1182466143977"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save(\"/bilstm-with-intermediate-task-humor.h\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pfxrQD7Xl-cc",
        "outputId": "71e2323b-f92f-42c2-83cd-6ded90f1c211"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_4_layer_call_fn while saving (showing 5 of 8). These functions will not be directly callable after loading.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gen_wv_model = Word2Vec(gen_words, vector_size=500, window=3, min_count=1, workers=16)"
      ],
      "metadata": {
        "id": "JYfXu-htBH_e"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(gen_wv_model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-cf_G0T5BNyd",
        "outputId": "7afe7142-5eca-411f-b583-5811fe8a64e9"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Word2Vec<vocab=46908, vector_size=500, alpha=0.025>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# tokenizer = Tokenizer(46908)\n",
        "# tokenizer.fit_on_texts(gen_words)\n",
        "txt2 = tokenizer.texts_to_sequences(gen_words)\n",
        "txt2 = keras.utils.pad_sequences(txt2, 50)\n",
        "\n",
        "model = keras.models.Sequential([\n",
        "\n",
        "    # Embedding layer\n",
        "    keras.layers.Embedding(input_dim=len(imdb_wv_model.wv.key_to_index),\n",
        "                            output_dim=500,\n",
        "                            input_length=50,\n",
        "                            weights=[imdb_wv_model.wv.vectors],\n",
        "                            trainable=True),\n",
        "    \n",
        "    keras.layers.Dropout(0.2),\n",
        "\n",
        "    # BiLSTM layer\n",
        "    keras.layers.Bidirectional(keras.layers.LSTM(128, return_sequences=True)),\n",
        "\n",
        "    keras.layers.Bidirectional(keras.layers.LSTM(64)),\n",
        "\n",
        "    keras.layers.Dropout(0.2),\n",
        "\n",
        "    keras.layers.Dense(200),\n",
        "\n",
        "    keras.layers.Activation('relu'),\n",
        "\n",
        "    keras.layers.Dropout(0.2),\n",
        "    \n",
        "    # Output layer\n",
        "    keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "\n",
        "y = gen_df[\"class\"]\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(np.array(txt2), np.array(y), train_size=0.8, stratify=y, random_state=42)\n",
        "\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy', keras.metrics.Precision(), keras.metrics.Recall()])\n",
        "\n",
        "model.fit(x_train, y_train, validation_data=(x_test, y_test), epochs=10, batch_size=64)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XKkAgrQOF-0I",
        "outputId": "1837f450-cc51-4e90-d79f-fc6b820e340b"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "118/118 [==============================] - 35s 223ms/step - loss: 0.4235 - accuracy: 0.8472 - precision_1: 0.8474 - recall_1: 0.9998 - val_loss: 0.4095 - val_accuracy: 0.8472 - val_precision_1: 0.8472 - val_recall_1: 1.0000\n",
            "Epoch 2/10\n",
            "118/118 [==============================] - 17s 143ms/step - loss: 0.4073 - accuracy: 0.8474 - precision_1: 0.8474 - recall_1: 1.0000 - val_loss: 0.4131 - val_accuracy: 0.8472 - val_precision_1: 0.8472 - val_recall_1: 1.0000\n",
            "Epoch 3/10\n",
            "118/118 [==============================] - 14s 116ms/step - loss: 0.2167 - accuracy: 0.9161 - precision_1: 0.9296 - recall_1: 0.9749 - val_loss: 0.5578 - val_accuracy: 0.8078 - val_precision_1: 0.8571 - val_recall_1: 0.9277\n",
            "Epoch 4/10\n",
            "118/118 [==============================] - 10s 85ms/step - loss: 0.0568 - accuracy: 0.9836 - precision_1: 0.9915 - recall_1: 0.9892 - val_loss: 0.6862 - val_accuracy: 0.7923 - val_precision_1: 0.8628 - val_recall_1: 0.8975\n",
            "Epoch 5/10\n",
            "118/118 [==============================] - 9s 77ms/step - loss: 0.0381 - accuracy: 0.9872 - precision_1: 0.9937 - recall_1: 0.9912 - val_loss: 0.7427 - val_accuracy: 0.7364 - val_precision_1: 0.8683 - val_recall_1: 0.8121\n",
            "Epoch 6/10\n",
            "118/118 [==============================] - 7s 62ms/step - loss: 0.0219 - accuracy: 0.9893 - precision_1: 0.9962 - recall_1: 0.9912 - val_loss: 0.7535 - val_accuracy: 0.7673 - val_precision_1: 0.8602 - val_recall_1: 0.8661\n",
            "Epoch 7/10\n",
            "118/118 [==============================] - 6s 54ms/step - loss: 0.0194 - accuracy: 0.9892 - precision_1: 0.9940 - recall_1: 0.9932 - val_loss: 0.9104 - val_accuracy: 0.6832 - val_precision_1: 0.8750 - val_recall_1: 0.7304\n",
            "Epoch 8/10\n",
            "118/118 [==============================] - 7s 55ms/step - loss: 0.0160 - accuracy: 0.9911 - precision_1: 0.9953 - recall_1: 0.9942 - val_loss: 0.9976 - val_accuracy: 0.6496 - val_precision_1: 0.8723 - val_recall_1: 0.6870\n",
            "Epoch 9/10\n",
            "118/118 [==============================] - 6s 48ms/step - loss: 0.0146 - accuracy: 0.9893 - precision_1: 0.9953 - recall_1: 0.9921 - val_loss: 0.9278 - val_accuracy: 0.7780 - val_precision_1: 0.8601 - val_recall_1: 0.8812\n",
            "Epoch 10/10\n",
            "118/118 [==============================] - 6s 52ms/step - loss: 0.0119 - accuracy: 0.9912 - precision_1: 0.9948 - recall_1: 0.9948 - val_loss: 1.1468 - val_accuracy: 0.6459 - val_precision_1: 0.8716 - val_recall_1: 0.6826\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f090fb83070>"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "val_recall = 0.8716 *100\n",
        "val_precision = 0.6826 *100\n",
        "val_f1 = (2 * val_precision * val_recall) / (val_precision + val_recall)\n",
        "\n",
        "val_f1"
      ],
      "metadata": {
        "id": "zzCxsmZkAuoD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e5decd9b-8c93-473a-9f13-2bed518f6b94"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "76.5608235748295"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r \"/bilstm.zip\" \"/bert-with-intermediate-task.h\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "llUwZ02NtfpW",
        "outputId": "c380ba45-0100-4957-9157-e8f186db2d37"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: bert-with-intermediate-task.h/ (stored 0%)\n",
            "  adding: bert-with-intermediate-task.h/assets/ (stored 0%)\n",
            "  adding: bert-with-intermediate-task.h/keras_metadata.pb (deflated 92%)\n",
            "  adding: bert-with-intermediate-task.h/variables/ (stored 0%)\n",
            "  adding: bert-with-intermediate-task.h/variables/variables.index (deflated 67%)\n",
            "  adding: bert-with-intermediate-task.h/variables/variables.data-00000-of-00001 (deflated 48%)\n",
            "  adding: bert-with-intermediate-task.h/fingerprint.pb (stored 0%)\n",
            "  adding: bert-with-intermediate-task.h/saved_model.pb (deflated 90%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ehjAu4Urt4zE"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}